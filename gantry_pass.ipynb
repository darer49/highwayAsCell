{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import  pandas as pd\n",
    "\n",
    "base_dir =\"H:\\文档\\门架收费站研究\"\n",
    "gantry_path = \"2023年3~4整合门架\"\n",
    "toll_path = \"2023年3~4整合出入口\"\n",
    "gantries = [\"4D2806\",\"4D2805\",\"4D2804\"]\n",
    "toll_stations = [\"广东市南路站\",\"广东亚运城站\"]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime(2023, 3, 1, 0, 0)\n",
    "end_date = datetime(2023, 4, 30, 12, 0)\n",
    "interval = timedelta(minutes=1)\n",
    "current_date = start_date\n",
    "minute_time_list = []\n",
    "# 遍历一天的时间并格式化为字符串\n",
    "while current_date <= end_date:  # 假设要遍历的日期是2月10日\n",
    "    formatted_time = current_date.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    minute_time_list.append(formatted_time)\n",
    "    current_date += interval\n",
    "minute_time_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 读取文本文件内容\n",
    "import os\n",
    "gantry_df_list = []\n",
    "folder_path1 = f\"{base_dir}\\\\{gantry_path}\"\n",
    "for gp in [os.path.join(folder_path1, file_name) for file_name in os.listdir(folder_path1)]:\n",
    "    with open(gp, 'r',encoding=\"utf-8\") as file:\n",
    "        data_text = file.read()\n",
    "    data_json = [json.loads(line) for line in data_text.strip().split('\\n')]\n",
    "    gantry_df_list.append(pd.DataFrame(data_json))\n",
    "gantry_df0  = pd.concat(gantry_df_list)\n",
    "\n",
    "gantry_df0.columns = [\"pass_id\",\"l\"]\n",
    "gantry_df_list = []\n",
    "for row in gantry_df0.itertuples():\n",
    "    new_row = {\"pass_id\":getattr(row,'pass_id')}\n",
    "    gantry_l = getattr(row,'l').split(\",\")\n",
    "    if len(gantry_l)==3:\n",
    "        new_row[\"l1\"] = gantry_l[0].replace(\"[\",\"\").replace(\"\\\\\",\"\").replace(\"\\\"\",\"\").replace(\"]\",\"\").replace(\"\\\"\",\"\")\n",
    "        new_row[\"l2\"] = gantry_l[1].replace(\"[\",\"\").replace(\"\\\\\",\"\").replace(\"\\\"\",\"\").replace(\"]\",\"\").replace(\"\\\"\",\"\")\n",
    "        new_row[\"l3\"] = gantry_l[2].replace(\"[\",\"\").replace(\"\\\\\",\"\").replace(\"\\\"\",\"\").replace(\"]\",\"\").replace(\"\\\"\",\"\")\n",
    "    elif len(gantry_l)==2:\n",
    "        new_row[\"l1\"] = gantry_l[0].replace(\"[\",\"\").replace(\"\\\\\",\"\").replace(\"\\\"\",\"\").replace(\"]\",\"\").replace(\"\\\"\",\"\")\n",
    "        new_row[\"l2\"] = gantry_l[1].replace(\"[\",\"\").replace(\"\\\\\",\"\").replace(\"\\\"\",\"\").replace(\"]\",\"\").replace(\"\\\"\",\"\")\n",
    "        new_row[\"l3\"] = \"\"\n",
    "    else:\n",
    "        new_row[\"l1\"] = gantry_l[0].replace(\"[\",\"\").replace(\"\\\\\",\"\").replace(\"\\\"\",\"\").replace(\"]\",\"\").replace(\"\\\"\",\"\")\n",
    "        new_row[\"l2\"] = \"\"\n",
    "        new_row[\"l3\"] = \"\"\n",
    "    gantry_df_list.append(new_row)\n",
    "gantry_df = pd.DataFrame(gantry_df_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gantry_df_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "gantry_df[\"l1_time\"] = \"\"\n",
    "gantry_df[\"l1_time\"] =  gantry_df[\"l1\"].agg(lambda x:x.split(\"----\")[0]  if x!=\"\" else \"\")\n",
    "gantry_df[\"l1_gantry\"]= gantry_df[\"l1\"].agg(lambda x:x.split(\"----\")[1]  if x!=\"\" else \"\")\n",
    "gantry_df[\"l2_time\"] =  gantry_df[\"l2\"].agg(lambda x:x.split(\"----\")[0]  if x!=\"\" else \"\")\n",
    "gantry_df[\"l2_gantry\"]= gantry_df[\"l2\"].agg(lambda x:x.split(\"----\")[1]  if x!=\"\" else \"\")\n",
    "gantry_df[\"l3_time\"] =  gantry_df[\"l3\"].agg(lambda x:x.split(\"----\")[0]  if x!=\"\" else \"\")\n",
    "gantry_df[\"l3_gantry\"]= gantry_df[\"l3\"].agg(lambda x:x.split(\"----\")[1]  if x!=\"\" else \"\")\n",
    "gantry_df[\"total\"]= gantry_df[\"l1\"]+gantry_df[\"l3\"]+gantry_df[\"l3\"]\n",
    "# gantry_df2 = gantry_df.query(\"l1_gantry=='4D290A' or l2_gantry=='4D290A' or l3_gantry=='4D290A'\")\n",
    "a_list = gantry_df.query(f\"l1_gantry=='{gantries[0]}'\")[\"l1_time\"].to_list()+gantry_df.query(f\"l2_gantry=='{gantries[0]}'\")[\"l2_time\"].to_list()+gantry_df.query(f\"l3_gantry=='{gantries[0]}'\")[\"l3_time\"].to_list()\n",
    "a_df = pd.DataFrame({\"time\":a_list,\"value\":[x for x in range(len(a_list))]})\n",
    "grouped  = a_df.groupby(\"time\").count()\n",
    "sorted_df = grouped.sort_values(by='value', ascending=False)\n",
    "print(sorted_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gantry_array = gantry_df[[\"pass_id\",\"l1\",\"l2\",\"l3\"]].to_numpy()\n",
    "\n",
    "new_gantry_df_list = []\n",
    "for row in gantry_array:\n",
    "    row_dict = {\"pass_id\":row[0]}\n",
    "    for gantry in gantries:\n",
    "        row_dict[\"gantry_\"+gantry] = \"no\"\n",
    "        row_dict[\"time_\"+gantry] = \"no\"\n",
    "    for record in row[1:]:\n",
    "        for gantry in gantries:\n",
    "            if gantry in record:\n",
    "                row_dict[\"gantry_\"+gantry]  = gantry\n",
    "                row_dict[\"time_\"+gantry]  = record.split(\"----\")[0]\n",
    "    new_gantry_df_list.append(row_dict)\n",
    "new_gantry_df = pd.DataFrame(new_gantry_df_list)\n",
    "new_gantry_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_gantry_df = new_gantry_df.query(f\"(time_{gantries[0]} >= '{minute_time_list[0]}' and time_{gantries[0]} <='{minute_time_list[-1]}') or (time_{gantries[0]} =='no' and time_{gantries[1]}>= '{minute_time_list[0]}' and time_{gantries[1]} <='{minute_time_list[-1]}') or  (time_{gantries[0]} =='no' and time_{gantries[1]}=='no' and time_{gantries[2]}>= '{minute_time_list[0]}' and time_{gantries[2]} <='{minute_time_list[-1]}')\")\n",
    "final_gantry_df = final_gantry_df.sort_values(by=f'time_{gantries[0]}')\n",
    "conditions = [f\"gantry_{gantries[0]} != 'no'\",\n",
    "              f\"gantry_{gantries[0]} == 'no'\",\n",
    "              f\"gantry_{gantries[1]} != 'no'\",\n",
    "              f\"gantry_{gantries[1]} == 'no'\",\n",
    "              f\"gantry_{gantries[2]} != 'no'\",\n",
    "              f\"gantry_{gantries[2]} == 'no'\"]\n",
    "con_ABC = final_gantry_df.query(f\"{conditions[0]} and {conditions[2]} and {conditions[4]}\")\n",
    "con_AB = final_gantry_df.query(f\"{conditions[0]} and {conditions[2]} and {conditions[5]}\")\n",
    "con_A = final_gantry_df.query(f\"{conditions[0]} and {conditions[3]} and {conditions[5]}\")\n",
    "con_BC = final_gantry_df.query(f\"{conditions[1]} and {conditions[2]} and {conditions[4]}\")\n",
    "con_B = final_gantry_df.query(f\"{conditions[1]} and {conditions[2]} and {conditions[5]}\")\n",
    "con_C = final_gantry_df.query(f\"{conditions[1]} and {conditions[3]} and {conditions[4]}\")\n",
    "cons = {'C123':con_ABC,'C12':con_AB,'C1':con_A,'C23':con_BC,'C2':con_B,'C3':con_C}\n",
    "con_ABC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "toll_df_list = []\n",
    "folder_path2 = f\"{base_dir}\\\\{toll_path}\"\n",
    "for tp in [os.path.join(folder_path2, file_name) for file_name in os.listdir(folder_path2)]:\n",
    "    with open(tp, 'r',encoding='utf-8') as file:\n",
    "        data_text2 = file.read()\n",
    "    data_json2 = [json.loads(line) for line in data_text2.strip().split('\\n')]\n",
    "    toll_df_list.append(pd.DataFrame(data_json2))\n",
    "\n",
    "toll_df= pd.concat(toll_df_list)\n",
    "\n",
    "toll_df[\"en_time\"] = toll_df[\"en_mess\"].agg(lambda x: x.split(\"----\")[0])\n",
    "toll_df[\"en_station\"] = toll_df[\"en_mess\"].agg(lambda x: x.split(\"----\")[1])\n",
    "toll_df[\"ex_time\"] = toll_df[\"ex_mess\"].agg(lambda x: x.split(\"----\")[0])\n",
    "toll_df[\"ex_station\"] = toll_df[\"ex_mess\"].agg(lambda x: x.split(\"----\")[1])\n",
    "for k,v in cons.items():\n",
    "    cons[k] = pd.merge(left=v,right=toll_df,on=\"pass_id\",how=\"left\").fillna(\"no\")\n",
    "    cons[k].to_csv(f\"res/{k}.csv\",index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cons['C123_0_c'] = cons['C123'].query(f\"ex_station=='{toll_stations[2]}'\")\n",
    "# cons['C123_0_0'] = cons['C123'].query(f\"ex_station=='no'\")\n",
    "cons['C12_0_b'] = cons['C12'].query(f\"ex_station=='{toll_stations[1]}'\")\n",
    "cons['C1_0_a'] = cons['C123'].query(f\"ex_station=='{toll_stations[0]}'\")\n",
    "# cons['C23_a_0'] = cons['C23'].query(f\"en_station=='{toll_stations[0]}' and ex_station=='no'\")\n",
    "# cons['C23_a_c'] = cons['C23'].query(f\"en_station=='{toll_stations[0]}' and ex_station=='{toll_stations[2]}'\")\n",
    "cons['C2_a_b'] = cons['C23'].query(f\"en_station=='{toll_stations[0]}' and ex_station=='{toll_stations[1]}'\")\n",
    "cons['C3_b_0'] = cons['C3'].query(f\"en_station=='{toll_stations[1]}'\")\n",
    "# cons['C3_b_c'] = cons['C3'].query(f\"en_station=='{toll_stations[1]}' and ex_station=='{toll_stations[2]}'\")\n",
    "cons['C12_0_b']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import  pyperclip\n",
    "# pyperclip.copy(str([str(x) for x in cons['C12'].query(\"en_station=='no' and ex_station=='no'\")['pass_id'].to_list()]))\n",
    "# cons['C123']\n",
    "# len_calcu = {k:str(len(v.query(\"en_station=='no' and ex_station=='no'\")))+\"/\"+str(len(v)) for k,v in cons.items()}\n",
    "# len_calcu\n",
    "cons[\"Ca\"] = cons[\"C\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 各个分钟有多少个各个条件的车通过\n",
    "minute_nums = []\n",
    "for minute in minute_time_list:\n",
    "    con_nums = {\"time\":minute}\n",
    "    for k,v in cons.items():\n",
    "        con_nums[k] = len(v.query(f\"time_{gantries[int(k[1])-1]}==@minute\"))\n",
    "    minute_nums.append(con_nums)\n",
    "pd.DataFrame(minute_nums)\n",
    "import pickle\n",
    "with open(\"res/minute_res.pkl\",\"wb\") as f:\n",
    "    pickle.dump(minute_nums,f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
